---
title: AI Tool
emoji: ðŸš€
colorFrom: indigo
colorTo: purple
sdk: docker
app_port: 7860
pinned: false
---

# Document Intelligence & RAG System

This project is a sophisticated Retrieval-Augmented Generation (RAG) platform designed to ingest, analyze, and query complex unstructured and structured data sources. It transforms static documents (PDF, Excel, CSV) into a queryable knowledge base using advanced vectorization techniques and Large Language Models (LLMs).

## Methodology and Algorithms

The core of this system relies on a specialized Dual-Stream RAG Architecture designed to maximize retrieval accuracy and minimize hallucinations.

### 1. Dual-Stream RAG Architecture
Unlike standard RAG implementations that treat all document content uniformly, this system employs a dual-stream approach:
*   **Narrative Stream**: Textual content is segmented into semantically coherent chunks. These chunks are processed to preserve paragraph context.
*   **Structured Data Stream**: Tables and spreadhseet data are effectively isolated. This prevents the "flattening" loss often seen when tables are converted to simple text.

### 2. Vectorization and Embeddings
*   **Algorithm**: The system utilizes high-dimensional dense vector embeddings generated by **Sentence-Transformers**.
*   **Model**: We employ optimized embedding models to convert text chunks into vector space representations.
*   **Indexing**: Vectors are stored and indexed using **FAISS (Facebook AI Similarity Search)**. FAISS enables efficient similarity search and clustering of dense vectors, allowing for millisecond-latency retrieval even with large datasets.

### 3. Neuromorphic Reasoning Environment
*   **LLM Integration**: The reasoning layer is powered by **Gemini 2.0 Flash**. This model is selected for its high reasoning capabilities and large context window.
*   **Context Injection**: Retrieved vector matches are dynamically ranking and injected into the LLM's context window.
*   **Query Rewriting**: To handle multi-turn conversations, the system uses an algorithmic approach to rewrite user queries based on conversation history (e.g., resolving coreference resolution like "details of him").

### 4. Data Processing Pipeline
*   **PDF Extraction**: **PyMuPDF** is used for low-level access to PDF structures, allowing for the precise coordinate-based extraction of text and tables.
*   **Data Normalization**: Pandas is utilized for normalizing tabular data from CSV and Excel sources before vectorization.

## Features

*   **Intelligent Querying**: Context-aware Q&A capable of synthesizing answers from multiple document sections.
*   **Statistical Analysis**: Automatic generation of statistical visualizations (Bar, Line, Pie, Scatter plots) using Matplotlib and Seaborn based on data interpretation.
*   **Session Management**: Persistent storage of chat sessions and user interactions using Firebase Realtime Database.
*   **Flashcard Generation**: Algorithmic extraction of key concepts to generate reviewable flashcards.
*   **Citation Engine**: Every generated response includes specific references to the source document segments to ensure verifiability.

## Technology Stack

*   **Frontend**: HTML5, Vanilla JavaScript, CSS3
*   **Backend**: Python (Flask)
*   **AI/ML**: LangChain (Orchestration), FAISS (Vector Store), Google Gemini API (Inference)
*   **Data**: Firebase Realtime Database
*   **Utilities**: PyMuPDF, Pandas, NumPy

## Setup and Installation

### Prerequisites
*   Python 3.9 or higher
*   Google Gemini API Key
*   Firebase Realtime Database URL

### Installation

1.  Clone the repository:
    ```bash
    git clone [repository-url]
    cd RAG
    ```

2.  Install required Python packages:
    ```bash
    pip install -r requirements.txt
    ```

3.  Configuration:
    Create a `.env` file or update `app.py` with the following variables:
    ```
    GEMINI_API_KEY=your_api_key
    FIREBASE_URL=your_firebase_url
    ```

### Running the Application

1.  Start the Flask server:
    ```bash
    python app.py
    ```

2.  Access the interface via a web browser at:
    `http://127.0.0.1:5000`

## Troubleshooting

### Network Errors
If the application experiences connection resets or network errors during large file processing, it is often due to the Flask reloader in development mode. Run the application with the reloader disabled:

```bash
python app.py --no-reload
```
